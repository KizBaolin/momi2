{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 466M\r\n",
      "lrwxrwxrwx 1 jk21 team118   54 Jan 11 14:45 raw -> /lustre/scratch115/projects/ancientgen/dg11/data_final\r\n",
      "-rw-r--r-- 1 jk21 team118 465M Jan 11 14:46 subsample.frq.strat\r\n",
      "-rw-r--r-- 1 jk21 team118  32K Jan 11 14:41 subsample-individuals.txt\r\n",
      "-rw-r--r-- 1 jk21 team118 1.2K Jan 11 14:46 subsample.log\r\n",
      "-rw-r--r-- 1 jk21 team118 2.6K Jan 11 14:46 subsample.nosex\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b3.44 64-bit (17 Nov 2016)      https://www.cog-genomics.org/plink2\n",
      "(C) 2005-2016 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to scratch/subsample.log.\n",
      "Options in effect:\n",
      "  --allow-no-sex\n",
      "  --bfile scratch/raw/newhumori_ancSA_lazar_norel_crgr10_Tvonly\n",
      "  --freq\n",
      "  --keep scratch/subsample-individuals.txt\n",
      "  --out scratch/subsample\n",
      "  --within scratch/subsample-individuals.txt\n",
      "\n",
      "257853 MB RAM detected; reserving 128926 MB for main workspace.\n",
      "Allocated 4083 MB successfully, after larger attempt(s) failed.\n",
      "96623 variants loaded from .bim file.\n",
      "2363 people (1489 males, 718 females, 156 ambiguous) loaded from .fam.\n",
      "Ambiguous sex IDs written to scratch/subsample.nosex .\n",
      "42 phenotype values loaded from .fam.\n",
      "--keep: 1530 people remaining.\n",
      "--within: 78 clusters loaded, covering a total of 1530 people.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 1530 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 0%\b\b1%\b\b2%\b\b3%\b\b4%\b\b5%\b\b6%\b\b7%\b\b8%\b\b9%\b\b10%\b\b\b11%\b\b\b12%\b\b\b13%\b\b\b14%\b\b\b15%\b\b\b16%\b\b\b17%\b\b\b18%\b\b\b19%\b\b\b20%\b\b\b21%\b\b\b22%\b\b\b23%\b\b\b24%\b\b\b25%\b\b\b26%\b\b\b27%\b\b\b28%\b\b\b29%\b\b\b30%\b\b\b31%\b\b\b32%\b\b\b33%\b\b\b34%\b\b\b35%\b\b\b36%\b\b\b37%\b\b\b38%\b\b\b39%\b\b\b40%\b\b\b41%\b\b\b42%\b\b\b43%\b\b\b44%\b\b\b45%\b\b\b46%\b\b\b47%\b\b\b48%\b\b\b49%\b\b\b50%\b\b\b51%\b\b\b52%\b\b\b53%\b\b\b54%\b\b\b55%\b\b\b56%\b\b\b57%\b\b\b58%\b\b\b59%\b\b\b60%\b\b\b61%\b\b\b62%\b\b\b63%\b\b\b64%\b\b\b65%\b\b\b66%\b\b\b67%\b\b\b68%\b\b\b69%\b\b\b70%\b\b\b71%\b\b\b72%\b\b\b73%\b\b\b74%\b\b\b75%\b\b\b76%\b\b\b77%\b\b\b78%\b\b\b79%\b\b\b80%\b\b\b81%\b\b\b82%\b\b\b83%\b\b\b84%\b\b\b85%\b\b\b86%\b\b\b87%\b\b\b88%\b\b\b89%\b\b\b90%\b\b\b91%\b\b\b92%\b\b\b93%\b\b\b94%\b\b\b95%\b\b\b96%\b\b\b97%\b\b\b98%\b\b\b99%\b\b\b\b done.\n",
      "Total genotyping rate in remaining samples is 0.936546.\n",
      "--freq: Cluster-stratified allele frequencies (founders only) written to\n",
      "scratch/subsample.frq.strat .\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "plink --bfile scratch/raw/newhumori_ancSA_lazar_norel_crgr10_Tvonly \\\n",
    "    --keep scratch/subsample-individuals.txt \\\n",
    "    --within scratch/subsample-individuals.txt \\\n",
    "    --freq --out scratch/subsample --allow-no-sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7536595 scratch/subsample.frq.strat\n",
      " CHR           SNP     CLST   A1   A2      MAF    MAC  NCHROBS\n",
      "   1      1.842013    !Xuun    G    T   0.4231     11       26 \n",
      "   1      1.842013       AA    G    T     0.15      3       20 \n",
      "   1      1.842013   Adygei    G    T   0.3125     10       32 \n",
      "   1      1.842013 Anatolia_N    G    T   0.2143      6       28 \n",
      "   1      1.842013 Armenian    G    T     0.35      7       20 \n",
      "   1      1.842013 Assyrian    G    T   0.1364      3       22 \n",
      "   1      1.842013   Balkar    G    T      0.2      4       20 \n",
      "   1      1.842013  Balochi    G    T   0.2273     10       44 \n",
      "   1      1.842013 BantuKenya    G    T      0.1      2       20 \n"
     ]
    }
   ],
   "source": [
    "!wc -l scratch/subsample.frq.strat\n",
    "!head scratch/subsample.frq.strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import momi\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_plink_frq_strat(fname, ancestral_pop, chunk_size = 10000):\n",
    "    def get_chunks(locus_id, locus_rows):\n",
    "        snps_grouped = it.groupby(locus_rows, lambda r: r[1])\n",
    "        snps_enum = enumerate(list(snp_rows) for snp_id, snp_rows in snps_grouped)            \n",
    "\n",
    "        for chunk_num, chunk in it.groupby(snps_enum, lambda idx_snp_pair: idx_snp_pair[0] // chunk_size):\n",
    "            chunk = pd.DataFrame(list(it.chain.from_iterable(snp for snp_num, snp in chunk)),\n",
    "                                columns = header)\n",
    "            for col_name, col in chunk.ix[:,(\"MAC\",\"NCHROBS\")].items():\n",
    "                chunk[col_name] = [int(x) for x in col]\n",
    "\n",
    "            # check A1, A2 agrees for every row of every SNP\n",
    "            for a in (\"A1\",\"A2\"):\n",
    "                assert all(len(set(snp[a])) == 1 for _,snp in chunk.groupby([\"CHR\",\"SNP\"]))\n",
    "\n",
    "            # replace allele name with counts\n",
    "            chunk[\"A1\"] = chunk[\"MAC\"]\n",
    "            chunk[\"A2\"] = chunk[\"NCHROBS\"] - chunk[\"A1\"]\n",
    "\n",
    "            # drop extraneous columns, label indices\n",
    "            chunk = chunk.ix[:,[\"SNP\",\"CLST\",\"A1\",\"A2\"]]\n",
    "            chunk.set_index([\"SNP\",\"CLST\"], inplace=True)\n",
    "            chunk.columns.name = \"Allele\"\n",
    "\n",
    "            ## convert to 3d array (panel)\n",
    "            chunk = chunk.stack(\"Allele\").unstack(\"SNP\").to_panel()\n",
    "            assert chunk.shape[2] == 2\n",
    "            populations = list(chunk.axes[1])\n",
    "            chunk = chunk.values\n",
    "\n",
    "            ## polarize\n",
    "            # remove ancestral population\n",
    "            anc_pop_idx = populations.index(ancestral_pop)\n",
    "            anc_counts = chunk[:,anc_pop_idx,:]\n",
    "            chunk = np.delete(chunk, anc_pop_idx, axis=1)\n",
    "            populations.pop(anc_pop_idx)\n",
    "            # check populations are same as sampled_pops\n",
    "            if not sampled_pops:\n",
    "                sampled_pops.extend(populations)\n",
    "            assert sampled_pops == populations\n",
    "\n",
    "            is_ancestral = [(anc_counts[:,allele] > 0) & (anc_counts[:,other_allele] == 0)\n",
    "                           for allele, other_allele in ((0,1),(1,0))]\n",
    "\n",
    "            assert np.all(~(is_ancestral[0] & is_ancestral[1]))\n",
    "            chunk[is_ancestral[1],:,:] = chunk[is_ancestral[1],:,::-1]\n",
    "            chunk = chunk[is_ancestral[0] | is_ancestral[1],:,:]\n",
    "\n",
    "            # remove monomorphic sites\n",
    "            polymorphic = (chunk.sum(axis=1) > 0).sum(axis=1) == 2\n",
    "            chunk = chunk[polymorphic,:,:]\n",
    "\n",
    "            yield chunk\n",
    "        logging.info(\"Finished reading CHR {}\".format(locus_id))\n",
    "\n",
    "    with open(fname) as f:\n",
    "        rows = (l.split() for l in f)\n",
    "        header = next(rows)\n",
    "        assert header[:2] == [\"CHR\", \"SNP\"]\n",
    "\n",
    "        loci = (it.chain.from_iterable(get_chunks(locus_id, locus_rows))\n",
    "                   for locus_id, locus_rows in it.groupby(rows, lambda r: r[0]))\n",
    "        \n",
    "        # sampled_pops is not read until the first chunk is processed\n",
    "        sampled_pops = []        \n",
    "        first_loc = next(loci)\n",
    "        first_chunk = next(first_loc)\n",
    "        \n",
    "        # add the first chunk/locus back onto the iterators\n",
    "        first_loc = it.chain([first_chunk], first_loc)\n",
    "        loci = it.chain([first_loc], loci)\n",
    "        \n",
    "        return momi.seg_site_configs(sampled_pops, loci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Finished reading CHR 1\n",
      "INFO:root:Finished reading CHR 2\n",
      "INFO:root:Finished reading CHR 3\n",
      "INFO:root:Finished reading CHR 4\n",
      "INFO:root:Finished reading CHR 5\n",
      "INFO:root:Finished reading CHR 6\n",
      "INFO:root:Finished reading CHR 7\n",
      "INFO:root:Finished reading CHR 8\n",
      "INFO:root:Finished reading CHR 9\n",
      "INFO:root:Finished reading CHR 10\n",
      "INFO:root:Finished reading CHR 11\n",
      "INFO:root:Finished reading CHR 12\n",
      "INFO:root:Finished reading CHR 13\n",
      "INFO:root:Finished reading CHR 14\n",
      "INFO:root:Finished reading CHR 15\n",
      "INFO:root:Finished reading CHR 16\n",
      "INFO:root:Finished reading CHR 17\n",
      "INFO:root:Finished reading CHR 18\n",
      "INFO:root:Finished reading CHR 19\n",
      "INFO:root:Finished reading CHR 20\n",
      "INFO:root:Finished reading CHR 21\n",
      "INFO:root:Finished reading CHR 22\n"
     ]
    }
   ],
   "source": [
    "seg_sites = read_plink_frq_strat(\"scratch/subsample.frq.strat\", \"Chimp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"scratch/ancestral_counts.txt\",\"w\") as f:\n",
    "    print(\"CHR\", *seg_sites.sampled_pops, file=f)\n",
    "    for i,loc in enumerate(seg_sites):\n",
    "        for site in loc:\n",
    "            print(i+1, *site[:,0], file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"scratch/derived_counts.txt\",\"w\") as f:\n",
    "    print(\"CHR\", *seg_sites.sampled_pops, file=f)\n",
    "    for i,loc in enumerate(seg_sites):\n",
    "        for site in loc:\n",
    "            print(i+1, *site[:,1], file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!diff scratch/ancestral_counts.txt scratch/ancestral_counts.txt.bak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!diff scratch/derived_counts.txt scratch/derived_counts.txt.bak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
