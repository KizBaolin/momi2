{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import momi\n",
    "import pandas\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the **`help()`** function to view documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package momi:\n",
      "\n",
      "NAME\n",
      "    momi\n",
      "\n",
      "FILE\n",
      "    /Users/jkamm/anaconda/lib/python2.7/site-packages/momi/__init__.py\n",
      "\n",
      "DESCRIPTION\n",
      "    momi (MOran Models for Inference) is a python package for computing the site frequency spectrum,\n",
      "    a summary statistic commonly used in population genetics, and using it to infer demographic history.\n",
      "    \n",
      "    Please refer to examples/tutorial.py for usage & introduction.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    compress_sfs\n",
      "    compute_sfs\n",
      "    convolution\n",
      "    demography\n",
      "    likelihood\n",
      "    likelihood_surface\n",
      "    math_functions\n",
      "    moran_model\n",
      "    parse_ms\n",
      "    simulate_inference\n",
      "    size_history\n",
      "    tensor\n",
      "    util\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(momi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating demographies\n",
    "\n",
    "momi uses a syntax based on the program ms by Richard Hudson.\n",
    "A demography is specified as a sequence of events.\n",
    "Time is measured going backwards from the present (t=0) to the past (t>0).\n",
    "\n",
    "There are 4 kinds of events:\n",
    "* **('-en', t, i, N)**\n",
    "    * At time t, population i has its scaled population size set to N, and growth rate set to 0.\n",
    "* **('-eg', t, i, g)**\n",
    "    * At time t, population i has exponential growth rate g (so for s>t, $N(s) = N(t) e^{(s-t)  g}$)\n",
    "* **('-ej', t, i, j)**\n",
    "    * At time t, all lineages in population i move into j.\n",
    "* **('-ep', t, i, j, p_ij)**\n",
    "    * At time t, each lineage in i moves into j with probability p_ij.\n",
    "\n",
    "Note **-en,-eg,-ej** are flags from ms, while **-ep** replaces the flag **-es** in ms.\n",
    "By default, all parameters are scaled as in ms, but this can be adjusted.\n",
    "\n",
    "See **`help(momi.Demography)`** or **`help(momi.Demography.__init__)`** for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example demography\n",
    "\n",
    "Now let's consider a concrete example. More examples can be found at [example_demographies.ipynb](files/example_demographies.ipynb).\n",
    "\n",
    "Unlike ms, populations can be labeled by arbitrary strings. In this example, we'll label the sampled populations as **'chb'** and **'yri'**. The demography will also involve admixture with a third population, **'nea'**.\n",
    "\n",
    "Using the default parameter scaling (which is the same as **ms**),\n",
    "we assume that all population sizes have been rescaled by a \"reference\" size N_ref (e.g. 10,000),\n",
    "and time is scaled so there are 4*N_ref generations per unit time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the list of events\n",
    "events = [('-en', 0., 'chb', 10.),         # at present (t=0), 'chb' has diploid population size 10 * N_ref\n",
    "          ('-eg', 0, 'chb' , 6.),          # at present (t=0), 'chb' growing at rate 6\n",
    "          ('-ep', .25, 'chb', 'nea', .03), # at t=.25, 'chb' has a bit of admixture from 'nea'\n",
    "          ('-ej', .5, 'chb', 'yri'),       # at t=.5, 'chb' joins onto 'yri' \n",
    "          ('-ej', 1.5, 'yri', 'nea'),      # at t=1.5, 'yri' joins onto 'nea'\n",
    "          ]\n",
    "\n",
    "# construct the Demography object, sampling 14 alleles from 'yri' and 10 alleles from 'chb'\n",
    "demo = momi.Demography(events, sampled_pops=('yri','chb'), sampled_n=(14,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coalescent statistics\n",
    "\n",
    "Let's examine some statistics of the above demography, such as the TMRCA (time to most recent common ancestor) and total branch length of the genealogy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected TMRCA of all samples: \t1.41920517653\n",
      "Expected TMRCA of chb samples: \t1.25374295456\n",
      "Expected total branch length: \t7.93963743415\n"
     ]
    }
   ],
   "source": [
    "eTmrca = momi.expected_tmrca(demo)\n",
    "print \"Expected TMRCA of all samples:\", \"\\t\", eTmrca\n",
    "\n",
    "eTmrca_chb = momi.expected_deme_tmrca(demo, 'chb')\n",
    "print \"Expected TMRCA of chb samples:\", \"\\t\", eTmrca_chb\n",
    "\n",
    "eL = momi.expected_total_branch_len(demo)\n",
    "print \"Expected total branch length:\", \"\\t\", eL\n",
    "\n",
    "# See help(momi.expected_tmrca), etc. for more details.\n",
    "# Advanced users can use momi.expected_sfs_tensor_prod()\n",
    "# to compute these and many other summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Sample Frequency Spectrum (SFS)\n",
    "\n",
    "The expected SFS for configuration $(i_0,i_1,...)$ is the expected number of SNPs with $i_0$ derived alleles in population 0, $i_1$ derived alleles in population 1, etc.\n",
    "\n",
    "In the below example we use **`momi.expected_sfs()`** to compute the expected SFS for several configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.6309565   0.95647102  0.0048574   0.06108049  0.04371188  0.0046881 ]\n"
     ]
    }
   ],
   "source": [
    "# a list of configs (index0 == yri, index1 == chb)\n",
    "config_list = [(0,1), (1,0), (3,1), (0,10), (12,0), (2,2)]\n",
    "\n",
    "# the SFS entries corresponding to each config in config_list\n",
    "eSFS = momi.expected_sfs(demo, config_list, mut_rate=1.0)\n",
    "print eSFS\n",
    "\n",
    "# See help(momi.expected_sfs) for more options (e.g. folded SFS, sampling error, normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observed SFS\n",
    "\n",
    "The observed SFS gives the number of observed SNPs for each configuration.\n",
    "\n",
    "momi represents the observed SFS as a **dictionary**, mapping configs (tuples) to counts (ints).\n",
    "\n",
    "An existing dataset for 10,000 loci has already been stored in [tutorial_data.txt](tutorial_data.txt). We read it in and examine it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loci:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "data_file = \"tutorial_data.txt\"\n",
    "sfs_list = momi.read_sfs_list(data_file)\n",
    "\n",
    "# sfs_list is a list of the SFS at each of 10,000 loci\n",
    "print \"Number of loci:\"\n",
    "print len(sfs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFS at first locus:\n",
      "{(0, 1): 26, (3, 2): 1, (7, 0): 3, (2, 0): 2, (3, 0): 6, (6, 0): 1, (0, 2): 3, (11, 8): 3, (14, 1): 3, (0, 5): 1, (0, 10): 2, (5, 0): 1, (0, 4): 1, (0, 9): 1, (0, 3): 1, (0, 8): 1, (1, 0): 10, (11, 6): 2, (14, 0): 2}\n"
     ]
    }
   ],
   "source": [
    "print \"SFS at first locus:\"\n",
    "print sfs_list[0]\n",
    "\n",
    "# an SFS is represent as a dictionary, {config0: count0, config1: count1, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined SFS at all loci:\n",
      "{(7, 3): 89, (6, 9): 223, (12, 1): 92, (14, 4): 753, (13, 4): 87, (0, 7): 4971, (1, 6): 106, (0, 10): 26774, (3, 7): 143, (2, 5): 83, (8, 5): 88, (5, 8): 138, (4, 0): 22333, (10, 8): 132, (9, 0): 8237, (6, 7): 95, (5, 5): 90, (11, 5): 82, (10, 7): 107, (7, 6): 107, (6, 10): 1875, (12, 6): 105, (14, 1): 687, (13, 7): 121, (0, 4): 12375, (1, 1): 99, (4, 10): 1888, (3, 2): 69, (2, 6): 123, (8, 2): 78, (4, 5): 82, (9, 3): 78, (6, 0): 13671, (11, 0): 6145, (7, 5): 101, (14, 2): 681, (13, 10): 1768, (0, 1): 202357, (3, 1): 108, (9, 9): 193, (7, 8): 154, (14, 8): 3938, (13, 0): 4766, (12, 8): 136, (2, 1): 81, (8, 9): 239, (9, 4): 97, (5, 1): 95, (10, 3): 81, (7, 2): 102, (12, 2): 64, (11, 10): 1702, (14, 5): 979, (13, 3): 96, (1, 5): 85, (3, 6): 120, (2, 2): 85, (1, 10): 1741, (8, 6): 91, (4, 1): 112, (10, 9): 206, (9, 7): 97, (6, 4): 84, (5, 4): 76, (11, 4): 87, (10, 4): 105, (7, 1): 86, (12, 7): 105, (11, 9): 251, (14, 6): 1486, (13, 6): 94, (0, 5): 7916, (1, 0): 97090, (0, 8): 4672, (3, 5): 93, (2, 7): 119, (8, 3): 82, (5, 10): 1776, (4, 6): 118, (10, 10): 1755, (9, 2): 76, (6, 1): 101, (5, 7): 129, (11, 3): 76, (7, 4): 94, (12, 4): 85, (14, 3): 712, (13, 9): 207, (0, 2): 49455, (1, 3): 98, (4, 8): 171, (3, 0): 30162, (2, 8): 133, (9, 8): 127, (8, 0): 9481, (6, 2): 87, (14, 9): 6649, (12, 9): 216, (3, 10): 1688, (8, 10): 1937, (5, 0): 17445, (10, 0): 7430, (12, 3): 84, (13, 2): 60, (1, 4): 93, (3, 9): 208, (2, 3): 85, (1, 9): 235, (8, 7): 119, (4, 2): 103, (9, 6): 95, (6, 5): 96, (5, 3): 72, (11, 7): 93, (10, 5): 92, (7, 0): 11561, (6, 8): 127, (12, 0): 5782, (11, 8): 120, (14, 7): 2250, (13, 5): 87, (0, 6): 5933, (1, 7): 129, (0, 9): 4863, (3, 4): 90, (2, 4): 84, (8, 4): 78, (5, 9): 198, (4, 7): 148, (9, 1): 72, (6, 6): 71, (5, 6): 99, (11, 2): 87, (10, 6): 83, (7, 7): 141, (12, 5): 71, (14, 0): 20652, (13, 8): 120, (0, 3): 21579, (1, 2): 71, (4, 9): 190, (3, 3): 71, (2, 9): 214, (8, 1): 85, (4, 4): 81, (6, 3): 71, (11, 1): 90, (7, 10): 1826, (12, 10): 1878, (2, 10): 1786, (9, 10): 1749, (10, 1): 95, (7, 9): 216, (13, 1): 101, (3, 8): 148, (2, 0): 46937, (1, 8): 135, (8, 8): 163, (4, 3): 72, (9, 5): 93, (5, 2): 79, (11, 6): 107, (10, 2): 72}\n"
     ]
    }
   ],
   "source": [
    "print \"Combined SFS at all loci:\"\n",
    "combined_sfs = momi.sum_sfs_list(sfs_list)\n",
    "print combined_sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mutations with configuration (1,0):\n",
      "97090\n"
     ]
    }
   ],
   "source": [
    "print \"Number of mutations with configuration (1,0):\"\n",
    "print combined_sfs[(1,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composite likelihood\n",
    "\n",
    "We construct a composite likelihood by using a Poisson random field (PRF) approximation.\n",
    "This assumes that the number of observed SNPs for each configuration are independent Poisson.\n",
    "\n",
    "Below we compute the composite likelihood of our dataset and demography, given a mutation rate of 10.0 per locus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite log likelihood: -67579.2634253\n"
     ]
    }
   ],
   "source": [
    "# the mutation rate per locus\n",
    "mut_rate_per_locus = 10.\n",
    "\n",
    "# the mutation rate for the whole dataset\n",
    "n_loci = len(sfs_list)\n",
    "combined_mut_rate = n_loci * mut_rate_per_locus\n",
    "\n",
    "composite_log_lik = momi.unlinked_log_likelihood(combined_sfs, demo, mut_rate=combined_mut_rate)\n",
    "print \"Composite log likelihood:\", composite_log_lik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic differentiation\n",
    "\n",
    "`momi` uses the package `autograd` to automatically compute derivatives.\n",
    "\n",
    "Gradients can be extremely useful in parameter inference.\n",
    "However, computing gradients is **not** strictly necessary for most functionality.\n",
    "Users who don't plan to use auto-differentiation can skip this section, or return to it later.\n",
    "\n",
    "Let's start by defining a function that maps some parameters to a demography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np ## thinly wrapped version of numpy for auto-differentiation\n",
    "\n",
    "def demo_func(N_chb_bottom, N_chb_top, pulse_t, pulse_p, ej_chb, ej_yri):\n",
    "    ej_chb = pulse_t + ej_chb\n",
    "    ej_yri = ej_chb + ej_yri\n",
    "    \n",
    "    # use autograd.numpy for math functions (e.g. logarithm)\n",
    "    # This will allow us to take derivatives later\n",
    "    G_chb = -np.log(N_chb_top / N_chb_bottom) / ej_chb\n",
    "    \n",
    "    events = [('-en', 0., 'chb', N_chb_bottom),\n",
    "              ('-eg', 0, 'chb' , G_chb),\n",
    "              ('-ep', pulse_t, 'chb', 'nea', pulse_p),\n",
    "              ('-ej', ej_chb, 'chb', 'yri'),\n",
    "              ('-ej', ej_yri, 'yri', 'nea'),\n",
    "              ]\n",
    "\n",
    "    return momi.Demography(events, ('yri','chb'), (14,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a function that returns the expected\n",
    "TMRCA from the parameters, and then use `autograd` to compute its gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "[10.0, 0.1, 0.25, 0.03, 0.25, 1.0]\n",
      "Expected TMRCA:\n",
      "1.31277716218\n",
      "Gradient:\n",
      "[0.0045248167517458011, 0.55838496083536993, 0.28449869706692488, 3.9671067152725357, 0.83175299796269708, 0.13916390098743361]\n"
     ]
    }
   ],
   "source": [
    "# function mapping vector of parameters to the TMRCA of the corresponding demography\n",
    "def tmrca_func(params):\n",
    "    # equivalent to demo_func(params[0], params[1], params[2], ...)\n",
    "    demo = demo_func(*params)\n",
    "    # return expected TMRCA\n",
    "    return momi.expected_tmrca(demo)\n",
    "\n",
    "# use autograd.grad() to obtain the gradient function\n",
    "from autograd import grad\n",
    "tmrca_grad = grad(tmrca_func)\n",
    "\n",
    "x = [10., .1, .25, .03, .25, 1.]\n",
    "print \"Parameters:\"\n",
    "print x\n",
    "print \"Expected TMRCA:\"\n",
    "print tmrca_func(x)\n",
    "print \"Gradient:\"\n",
    "print tmrca_grad(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More details about using `autograd` for automatic differentiation\n",
    "\n",
    "`autograd` uses the magic of *operator overloading* to compute derivatives automatically.\n",
    "\n",
    "Here are a few rules to keep in mind, to make sure `autograd` works correctly:\n",
    "\n",
    "* Arithmetic operations `+,-,*,/,**` all work with autograd\n",
    "\n",
    "* For more complicated mathematical operations, use `autograd.numpy` and `autograd.scipy`, thinly wrapped versions of `numpy` and `scipy` that support auto-differentiation.\n",
    "    * For most users, `numpy` contains all the mathematical operations that are needed: `exp()`, `log()`, trigonemetric functions, matrix operations, fourier transform, etc.\n",
    "    * If needed, it is also possible to use autograd to define derivatives of your own mathematical operations.\n",
    "* Other do's and don'ts: (copy and pasted from autograd tutorial)\n",
    "    * Do use\n",
    "        * Most of `numpy`'s functions\n",
    "        * Most `numpy.ndarray` methods\n",
    "        * Some `scipy` functions\n",
    "        * Indexing and slicing of arrays `x = A[3, :, 2:4]`\n",
    "        * Explicit array creation from lists `A = np.array([x, y])`\n",
    "    * Don't use\n",
    "        * Assignment to arrays `A[0,0] = x`\n",
    "        * Implicit casting of lists to arrays `A = numpy.sum([x, y])`, use `A = numpy.sum(np.array([x, y]))` instead.\n",
    "        * `A.dot(B)` notation (use `np.dot(A, B)` instead)\n",
    "        * In-place operations (such as `a += b`, use `a = a + b` instead)\n",
    "\n",
    "Documentation for autograd can be found at https://github.com/HIPS/autograd/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Now let's try to infer the following demography from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_params = [10., .1, .25, .03, .25, 1.]\n",
    "true_demo = demo_func(*true_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate a new dataset with `ms` (or similar program, e.g. `scrm`, `macs`, `msprime`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ms_path provided, using SFS previously stored in tutorial_data.txt.\n"
     ]
    }
   ],
   "source": [
    "## to generate new dataset, change this to\n",
    "## ms_path = \"/path/to/ms\"\n",
    "ms_path = None\n",
    "\n",
    "if ms_path is not None:\n",
    "    print \"Generating new dataset with ms\"\n",
    "    \n",
    "    n_loci, mut_rate_per_locus, recom_rate_per_locus = 10000, 10., 10.\n",
    "    \n",
    "    ms_output = momi.simulate_ms(ms_path, true_demo, \n",
    "                                 n_loci, mut_rate_per_locus, \n",
    "                                 additional_ms_params=\"-r %f 10000\" % recom_rate_per_locus)\n",
    "    sfs_list = momi.sfs_list_from_ms(ms_output)\n",
    "\n",
    "    combined_sfs = momi.sum_sfs_list(sfs_list)\n",
    "    combined_mut_rate = n_loci * mut_rate_per_locus\n",
    "    \n",
    "    ## uncomment this line to save the new dataset\n",
    "    #momi.write_sfs_list(sfs_list, data_file)\n",
    "else:\n",
    "    print \"No ms_path provided, using SFS previously stored in %s.\" % data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define (lower,upper) bounds on the parameter space\n",
    "bounds = [(.01, 100.),\n",
    "          (.01, 100.),\n",
    "          (.01,5.),\n",
    "          (.001,.25),\n",
    "          (.01,5.),\n",
    "          (.01,5.)]\n",
    "\n",
    "# pick a random start value for the parameter search\n",
    "import random\n",
    "lower_bounds, upper_bounds = [l for l,u in bounds], [u for l,u in bounds]\n",
    "start_params = [random.triangular(lower, upper, mode)\n",
    "                for lower, upper, mode in zip(lower_bounds, upper_bounds, [1, 1, 1, .1, 1,1,1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now search for the MCLE with `momi.unlinked_mle_search()`.\n",
    "\n",
    "By default, `momi.unlinked_mle_search()` assumes `demo_func` is differentiable with `autograd`, and uses the gradient in a hill-climbing algorithm.\n",
    "* If you don't want to use `autograd`, you can disable the gradient (i.e. jacobian) with:\n",
    "    * `momi.unlinked_mle_search(..., jac=False, ...)`\n",
    "* Conversely, `momi.unlinked_mle_search()` provides options for using the Hessian (second-order derivative), in addition to the gradient.\n",
    "    * See `help(momi.unlinked_mle_search)`.\n",
    "\n",
    "Beware that `momi.unlinked_mle_search()` can be vulnerable to local maxima.\n",
    "It isn't a problem in this example, but in other cases, you may have to try multiple starting positions to reach the global maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "objective ( [ 32.07686572  35.93110607   2.76977726   0.14485968   0.61600818   2.56761102] ) == 2.34621e+06\n",
      "iter 25\n",
      "objective ( [  7.96202564e-01   1.45976961e+01   6.88916031e-01   5.88225780e-02   1.00000000e-02   1.00000000e-02] ) == 96702.8\n",
      "iter 50\n",
      "objective ( [ 1.42369308  0.44158165  0.29680041  0.05825242  0.31992278  0.01      ] ) == 50679.1\n",
      "iter 75\n",
      "objective ( [ 6.38266067  0.10773648  0.17317568  0.04638007  0.3565005   0.52274802] ) == 2658.81\n",
      "iter 100\n",
      "objective ( [ 9.95820913  0.1010553   0.24771354  0.02994495  0.25438522  0.98704888] ) == 769.057\n",
      "iter 125\n",
      "objective ( [ 9.93544969  0.10158646  0.24789708  0.02965485  0.25484613  0.99444729] ) == 768.814\n"
     ]
    }
   ],
   "source": [
    "mcle_search_result = momi.unlinked_mle_search(combined_sfs, demo_func, combined_mut_rate, start_params, \n",
    "                                              bounds = bounds, maxiter = 500, output_progress = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results:\n",
      "  status: 2\n",
      " success: True\n",
      "    nfev: 129\n",
      "     fun: 768.81437521055341\n",
      "       x: array([ 9.93544964,  0.10158656,  0.24789711,  0.02965485,  0.25484617,\n",
      "        0.99444729])\n",
      " message: 'Converged (|x_n-x_(n-1)| ~= 0)'\n",
      "     jac: array([  5.22489881e-04,   1.26229927e-05,   1.23677773e-03,\n",
      "         4.07467537e-01,   4.54915639e-03,  -6.33379112e-04])\n",
      "     nit: 26\n"
     ]
    }
   ],
   "source": [
    "print \"Search results:\"\n",
    "# print info such as whether search succeeded, number function/gradient evaluations, etc\n",
    "print mcle_search_result\n",
    "# note the printed function & gradient values are for -1*log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated params:\n",
      "[ 9.93544964  0.10158656  0.24789711  0.02965485  0.25484617  0.99444729]\n",
      "Ratio of Estimated/Truth:\n",
      "[ 0.99354496  1.01586557  0.99158846  0.98849488  1.01938467  0.99444729]\n"
     ]
    }
   ],
   "source": [
    "est_params = mcle_search_result.x\n",
    "print \"Estimated params:\"\n",
    "print est_params\n",
    "print \"Ratio of Estimated/Truth:\"\n",
    "print est_params / true_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at estimated parameters: -768.814375211\n",
      "Log-likelihood at true parameters: -774.885651385\n"
     ]
    }
   ],
   "source": [
    "print \"Log-likelihood at estimated parameters:\", -mcle_search_result.fun\n",
    "print \"Log-likelihood at true parameters:\", momi.unlinked_log_likelihood(combined_sfs, true_demo, mut_rate=combined_mut_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Confidence Intervals\n",
    "\n",
    "As the number of independent loci goes to infinity,\n",
    "the MCLE is asymptotically Gaussian, with mean at the truth,\n",
    "and covariance given by the inverse 'Godambe information'.\n",
    "\n",
    "This can be used to construct approximate confidence intervals,\n",
    "which have the correct coverage properties in the limit (assuming certain regularity conditions, e.g. *identifiability* and *consistency*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing approximate covariance of MCLE...\n",
      "[[  2.53727567e-02  -2.24368132e-04   2.71444867e-04   1.14725781e-04\n",
      "   -4.58609258e-04  -1.50682514e-03]\n",
      " [ -2.24368132e-04   4.27654324e-06  -2.80645723e-06  -2.61300014e-06\n",
      "    4.59916259e-06   4.68172599e-05]\n",
      " [  2.71444867e-04  -2.80645723e-06   1.71937574e-05   3.40832616e-06\n",
      "   -1.82960528e-05  -1.06727642e-05]\n",
      " [  1.14725781e-04  -2.61300014e-06   3.40832616e-06   3.14499286e-06\n",
      "   -4.52473913e-06  -5.33580081e-05]\n",
      " [ -4.58609258e-04   4.59916259e-06  -1.82960528e-05  -4.52473913e-06\n",
      "    2.32418172e-05   2.61780696e-05]\n",
      " [ -1.50682514e-03   4.68172599e-05  -1.06727642e-05  -5.33580081e-05\n",
      "    2.61780696e-05   1.47242029e-03]]\n"
     ]
    }
   ],
   "source": [
    "print \"Computing approximate covariance of MCLE...\"\n",
    "\n",
    "## the approximate covariance matrix of the MCLE\n",
    "mcle_cov = momi.unlinked_mle_approx_cov(est_params, sfs_list, demo_func, mut_rate_per_locus)\n",
    "print mcle_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate 95% confidence intervals for parameters:\n",
      "      Lower      Upper  Truth\n",
      "0  9.623250  10.247649  10.00\n",
      "1  0.097533   0.105640   0.10\n",
      "2  0.239770   0.256024   0.25\n",
      "3  0.026179   0.033131   0.03\n",
      "4  0.245397   0.264295   0.25\n",
      "5  0.919239   1.069655   1.00\n"
     ]
    }
   ],
   "source": [
    "# marginal confidence intervals\n",
    "print \"Approximate 95% confidence intervals for parameters:\"\n",
    "\n",
    "import scipy.stats\n",
    "conf_lower, conf_upper = scipy.stats.norm.interval(.95, loc = est_params, scale = np.sqrt(np.diag(mcle_cov)))\n",
    "print pandas.DataFrame({\"Truth\" : true_params, \"Lower\" : conf_lower, \"Upper\" : conf_upper}, columns = [\"Lower\",\"Upper\",\"Truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest alpha, so that level-alpha confidence region contains Truth:\n",
      "(alpha = 0 is a single point, alpha = 1 is whole parameter space)\n",
      "alpha =  0.312401628989\n"
     ]
    }
   ],
   "source": [
    "# higher dimensional confidence regions, using wald test\n",
    "print \"Smallest alpha, so that level-alpha confidence region contains Truth:\"\n",
    "print \"(alpha = 0 is a single point, alpha = 1 is whole parameter space)\"\n",
    "\n",
    "# wald test: residual * cov^{-1} * residual should be Chi-squared with n_params degrees of freedom\n",
    "\n",
    "inv_cov = np.linalg.inv(mcle_cov)\n",
    "# make sure the numerical inverse is still symmetric\n",
    "assert np.allclose(inv_cov, inv_cov.T)\n",
    "inv_cov = (inv_cov + inv_cov.T) / 2.0\n",
    "\n",
    "resids = est_params - true_params\n",
    "wald_stat = np.dot(resids, np.dot(inv_cov, resids))\n",
    "print \"alpha = \", scipy.stats.chi2.cdf(wald_stat, df=len(resids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
