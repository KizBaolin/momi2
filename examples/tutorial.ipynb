{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import momi\n",
    "import pandas\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the **`help()`** function to view documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package momi:\n",
      "\n",
      "NAME\n",
      "    momi\n",
      "\n",
      "FILE\n",
      "    /home/snackattack/anaconda/lib/python2.7/site-packages/momi/__init__.py\n",
      "\n",
      "DESCRIPTION\n",
      "    momi (MOran Models for Inference) is a python package for computing the site frequency spectrum,\n",
      "    a summary statistic commonly used in population genetics, and using it to infer demographic history.\n",
      "    \n",
      "    Please refer to examples/tutorial.ipynb for usage & introduction.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    compute_sfs\n",
      "    convolution\n",
      "    data_structure\n",
      "    demography\n",
      "    likelihood\n",
      "    math_functions\n",
      "    moran_model\n",
      "    parse_ms\n",
      "    size_history\n",
      "    tensor\n",
      "    util\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(momi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating demographies\n",
    "\n",
    "momi uses a syntax based on the program ms by Richard Hudson.\n",
    "A demography is specified as a sequence of events.\n",
    "Time is measured going backwards from the present (t=0) to the past (t>0).\n",
    "\n",
    "There are 4 kinds of events:\n",
    "* **('-en', t, i, N)**\n",
    "    * At time t, population i has its scaled population size set to N, and growth rate set to 0.\n",
    "* **('-eg', t, i, g)**\n",
    "    * At time t, population i has exponential growth rate g (so for s>t, $N(s) = N(t) e^{(s-t)  g}$)\n",
    "* **('-ej', t, i, j)**\n",
    "    * At time t, all lineages in population i move into j.\n",
    "* **('-ep', t, i, j, p_ij)**\n",
    "    * At time t, each lineage in i moves into j with probability p_ij.\n",
    "\n",
    "Note **-en,-eg,-ej** are flags from ms, while **-ep** replaces the flag **-es** in ms.\n",
    "By default, all parameters are scaled as in ms, but this can be adjusted.\n",
    "\n",
    "See **`help(momi.Demography)`** or **`help(momi.Demography.__init__)`** for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example demography\n",
    "\n",
    "Now let's consider a concrete example. More examples can be found at [example_demographies.ipynb](files/example_demographies.ipynb).\n",
    "\n",
    "Unlike ms, populations can be labeled by arbitrary strings. In this example, we'll label the sampled populations as **'chb'** and **'yri'**. The demography will also involve admixture with a third population, **'nea'**.\n",
    "\n",
    "Using the default parameter scaling (which is the same as **ms**),\n",
    "we assume that all population sizes have been rescaled by a \"reference\" size N_ref (e.g. 10,000),\n",
    "and time is scaled so there are 4*N_ref generations per unit time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the list of events\n",
    "events = [('-en', 0., 'chb', 10.),         # at present (t=0), 'chb' has diploid population size 10 * N_ref\n",
    "          ('-eg', 0, 'chb' , 6.),          # at present (t=0), 'chb' growing at rate 6\n",
    "          ('-ep', .25, 'chb', 'nea', .03), # at t=.25, 'chb' has a bit of admixture from 'nea'\n",
    "          ('-ej', .5, 'chb', 'yri'),       # at t=.5, 'chb' joins onto 'yri' \n",
    "          ('-ej', 1.5, 'yri', 'nea'),      # at t=1.5, 'yri' joins onto 'nea'\n",
    "          ]\n",
    "\n",
    "# construct the Demography object, sampling 14 alleles from 'yri' and 10 alleles from 'chb'\n",
    "demo = momi.Demography(events, sampled_pops=('yri','chb'), sampled_n=(14,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coalescent statistics\n",
    "\n",
    "Let's examine some statistics of the above demography, such as the TMRCA (time to most recent common ancestor) and total branch length of the genealogy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected TMRCA of all samples: \t1.41920517653\n",
      "Expected TMRCA of chb samples: \t1.25374295456\n",
      "Expected total branch length: \t7.93963743415\n"
     ]
    }
   ],
   "source": [
    "eTmrca = momi.expected_tmrca(demo)\n",
    "print \"Expected TMRCA of all samples:\", \"\\t\", eTmrca\n",
    "\n",
    "eTmrca_chb = momi.expected_deme_tmrca(demo, 'chb')\n",
    "print \"Expected TMRCA of chb samples:\", \"\\t\", eTmrca_chb\n",
    "\n",
    "eL = momi.expected_total_branch_len(demo)\n",
    "print \"Expected total branch length:\", \"\\t\", eL\n",
    "\n",
    "# See help(momi.expected_tmrca), etc. for more details.\n",
    "# Advanced users can use momi.expected_sfs_tensor_prod()\n",
    "# to compute these and many other summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Sample Frequency Spectrum (SFS)\n",
    "\n",
    "The expected SFS for configuration $((a_0,d_0),(a_1,d_1),...)$ is the expected number of SNPs with $a_0$ ancestral and $d_0$ derived alleles in population 0, $a_1$ ancestral and $d_1$ derived alleles in population 1, etc.\n",
    "\n",
    "In the below example we use **`momi.expected_sfs()`** to compute the expected SFS for several configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.6309565   0.95647102  0.0048574   0.06108049  0.04371188  0.00323204]\n"
     ]
    }
   ],
   "source": [
    "# a list of configs (index0 == yri, index1 == chb)\n",
    "config_list = [( (14,0), (9,1), ), # 1 derived allele in chb\n",
    "               ( (13,1), (10,0), ), # 1 derived allele in yri \n",
    "               ( (11,3), (9,1),) , # 3 derived in yri, 1 derived in chb\n",
    "               ( (14,0), (0,10), ), # 0 derived in yri, all derived in chb\n",
    "               ( (2,12), (10,0), ), # 12 derived in yri, 0 derived in chb \n",
    "               ( (2,12), (2,8), ), # 12 derived in yri, 8 derived in chb\n",
    "               ]\n",
    "\n",
    "# the SFS entries corresponding to each config in config_list\n",
    "eSFS = momi.expected_sfs(demo, config_list, mut_rate=1.0)\n",
    "print eSFS\n",
    "\n",
    "# See help(momi.expected_sfs) for more options (e.g. folded SFS, sampling error, normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segregating sites\n",
    "\n",
    "A dataset of segregating sites has been stored in [tutorial_data.txt](tutorial_data.txt). The file is organized as follows:\n",
    "* Each locus starts with a line \"**//**\".\n",
    "* Subsequent lines correspond to segregating sites.\n",
    "    * The first column is the **position** of the site $x \\in [0,1]$.\n",
    "    * Subsequent columns give the **ancestral,derived** allele counts (respectively), in each population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position\t:\tyri\tchb\r\n",
      "\r\n",
      "//\r\n",
      "\r\n",
      "0.0\t:\t14,0\t7,3\r\n",
      "0.0007\t:\t13,1\t10,0\r\n",
      "0.001\t:\t0,14\t10,0\r\n",
      "0.0012\t:\t11,3\t10,0\r\n",
      "0.0012\t:\t14,0\t9,1\r\n",
      "0.0013\t:\t0,14\t10,0\r\n"
     ]
    }
   ],
   "source": [
    "# print first few lines in the shell\n",
    "!head tutorial_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the file with momi\n",
    "data_filename = \"tutorial_data.txt\"\n",
    "with open(data_filename,'r') as f:\n",
    "    seg_sites = momi.read_seg_sites(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`seg_sites` is a list, with each entry corresponding to a locus.  \n",
    "The i-th entry `seg_sites[i]` is a list of the `(position,config)` of each site.  \n",
    "So `seg_sites` looks something like this:  \n",
    "> `[[(position`$_{00}$ `, config`$_{00}$ `), (position`$_{01}$ `, config`$_{01}$ `), ...],`  \n",
    "> &nbsp;&nbsp;`[(position`$_{10}$ `, config`$_{10}$ `), (position`$_{11}$ `, config`$_{11}$ `), ...], ...]`\n",
    "\n",
    "In addition, `seg_sites` has an attribute `seg_sites.sampled_pops` giving the populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populations: ('yri', 'chb')\n",
      "Number of loci: 20\n",
      "Number of sites on 0th locus: 3525\n",
      "First 3 sites on the 0th locus:\n",
      "[(0.0, ((14, 0), (7, 3))), (0.0007, ((13, 1), (10, 0))), (0.001, ((0, 14), (10, 0)))]\n"
     ]
    }
   ],
   "source": [
    "print \"Populations:\", seg_sites.sampled_pops\n",
    "print \"Number of loci:\", len(seg_sites)\n",
    "print \"Number of sites on 0th locus:\", len(seg_sites[0])\n",
    "print \"First 3 sites on the 0th locus:\"\n",
    "print seg_sites[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observed SFS\n",
    "\n",
    "Now let's convert the list of segregating sites into SFS.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a list, with the SFS at each locus\n",
    "sfs_list = momi.get_sfs_list(seg_sites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "momi represents the SFS at each locus as a **dictionary**, mapping configs (tuples) to counts (ints).  \n",
    "So `sfs_list` looks something like this:  \n",
    "> `[{config`$_{00}$ `: count`$_{00}$ `, config`$_{01}$ ` : count`$_{01}$ `, ...},`  \n",
    "> &nbsp;&nbsp;`{config`$_{10}$ `: count`$_{10}$ `, config`$_{11}$ ` : count`$_{11}$ `, ...}, ...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{((2, 12), (10, 0)): 24, ((14, 0), (0, 10)): 122, ((2, 12), (0, 10)): 11, ((5, 9), (0, 10)): 9, ((9, 5), (5, 5)): 2, ((8, 6), (10, 0)): 42, ((12, 2), (8, 2)): 1, ((12, 2), (9, 1)): 3, ((10, 4), (0, 10)): 4, ((0, 14), (5, 5)): 4, ((7, 7), (3, 7)): 1, ((7, 7), (0, 10)): 6, ((0, 14), (7, 3)): 8, ((7, 7), (6, 4)): 2, ((5, 9), (9, 1)): 1, ((6, 8), (2, 8)): 1, ((7, 7), (1, 9)): 1, ((0, 14), (1, 9)): 51, ((13, 1), (2, 8)): 2, ((3, 11), (1, 9)): 1, ((11, 3), (0, 10)): 4, ((9, 5), (0, 10)): 5, ((11, 3), (1, 9)): 4, ((6, 8), (0, 10)): 6, ((10, 4), (2, 8)): 1, ((2, 12), (1, 9)): 1, ((7, 7), (7, 3)): 1, ((7, 7), (10, 0)): 55, ((9, 5), (10, 0)): 83, ((4, 10), (5, 5)): 1, ((5, 9), (10, 0)): 27, ((6, 8), (7, 3)): 1, ((1, 13), (3, 7)): 1, ((4, 10), (8, 2)): 1, ((14, 0), (3, 7)): 33, ((12, 2), (10, 0)): 270, ((11, 3), (10, 0)): 149, ((8, 6), (3, 7)): 1, ((4, 10), (6, 4)): 1, ((4, 10), (9, 1)): 1, ((4, 10), (10, 0)): 27, ((14, 0), (8, 2)): 226, ((14, 0), (6, 4)): 75, ((7, 7), (2, 8)): 2, ((5, 9), (6, 4)): 1, ((14, 0), (4, 6)): 33, ((4, 10), (1, 9)): 1, ((1, 13), (6, 4)): 1, ((4, 10), (0, 10)): 20, ((0, 14), (3, 7)): 23, ((3, 11), (5, 5)): 1, ((11, 3), (4, 6)): 1, ((14, 0), (2, 8)): 37, ((3, 11), (0, 10)): 4, ((4, 10), (2, 8)): 1, ((10, 4), (4, 6)): 1, ((1, 13), (4, 6)): 2, ((8, 6), (0, 10)): 7, ((8, 6), (2, 8)): 1, ((1, 13), (7, 3)): 1, ((9, 5), (1, 9)): 1, ((13, 1), (10, 0)): 412, ((13, 1), (4, 6)): 1, ((8, 6), (9, 1)): 2, ((9, 5), (3, 7)): 1, ((10, 4), (5, 5)): 1, ((13, 1), (7, 3)): 2, ((6, 8), (10, 0)): 39, ((14, 0), (9, 1)): 1092, ((3, 11), (10, 0)): 30, ((0, 14), (8, 2)): 13, ((6, 8), (8, 2)): 2, ((0, 14), (10, 0)): 131, ((9, 5), (7, 3)): 3, ((11, 3), (7, 3)): 2, ((0, 14), (6, 4)): 3, ((12, 2), (0, 10)): 4, ((8, 6), (5, 5)): 1, ((11, 3), (9, 1)): 2, ((10, 4), (10, 0)): 134, ((14, 0), (7, 3)): 111, ((14, 0), (5, 5)): 29, ((14, 0), (1, 9)): 38, ((3, 11), (2, 8)): 1, ((0, 14), (4, 6)): 14, ((13, 1), (6, 4)): 1, ((12, 2), (1, 9)): 1, ((6, 8), (4, 6)): 1, ((13, 1), (8, 2)): 1, ((2, 12), (4, 6)): 1, ((1, 13), (0, 10)): 3, ((12, 2), (3, 7)): 2, ((0, 14), (2, 8)): 10, ((5, 9), (1, 9)): 6, ((4, 10), (7, 3)): 1, ((12, 2), (5, 5)): 1, ((12, 2), (2, 8)): 1, ((3, 11), (3, 7)): 1, ((0, 14), (9, 1)): 5, ((5, 9), (7, 3)): 3, ((1, 13), (10, 0)): 11}\n"
     ]
    }
   ],
   "source": [
    "# The SFS at the 0th locus\n",
    "print sfs_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The combined SFS, across all loci\n",
    "combined_sfs = momi.sum_sfs_list(sfs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`combined_sfs` looks something like this:\n",
    "> `{config`$_0$ `: count`$_0$ `, config`$_1$ `: count`$_1$ `, ...}`\n",
    "\n",
    "Its entries can be accessed by  \n",
    "```\n",
    "combined_sfs[config]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sites with configuration ((13,1),(10,0),):\n",
      "9251\n"
     ]
    }
   ],
   "source": [
    "print \"Total number of sites with configuration ((13,1),(10,0),):\"\n",
    "print combined_sfs[((13,1),(10,0),)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composite likelihood\n",
    "\n",
    "The composite likelihood treats each site as independent.  \n",
    "`momi` provides 2 composite likelihoods:\n",
    "* **multinomial**: Fixed number of sites, each drawn from multinomial\n",
    "* **Poisson random field**: Random number of sites, drawn from Poisson distribution\n",
    "\n",
    "Here we illustrate the **multinomial** likelihood (the default). See **help(momi.composite_log_likelihood)** for more options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite log likelihood: -6855.05740059\n"
     ]
    }
   ],
   "source": [
    "print \"Composite log likelihood:\", momi.composite_log_likelihood(combined_sfs, demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic differentiation\n",
    "\n",
    "`momi` uses the package `autograd` to automatically compute derivatives.\n",
    "\n",
    "Gradients can be extremely useful in parameter inference.\n",
    "However, computing gradients is **not** necessary for much functionality.\n",
    "Users who don't plan to use auto-differentiation can skip this section, or return to it later.\n",
    "\n",
    "Let's start by defining a function that maps some parameters to a demography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np ## thinly wrapped version of numpy for auto-differentiation\n",
    "\n",
    "def demo_func(N_chb_bottom, N_chb_top, pulse_t, pulse_p, ej_chb, ej_yri):\n",
    "    ej_chb = pulse_t + ej_chb\n",
    "    ej_yri = ej_chb + ej_yri\n",
    "    \n",
    "    # use autograd.numpy for math functions (e.g. logarithm)\n",
    "    # This will allow us to take derivatives later\n",
    "    G_chb = -np.log(N_chb_top / N_chb_bottom) / ej_chb\n",
    "    \n",
    "    events = [('-en', 0., 'chb', N_chb_bottom),\n",
    "              ('-eg', 0, 'chb' , G_chb),\n",
    "              ('-ep', pulse_t, 'chb', 'nea', pulse_p),\n",
    "              ('-ej', ej_chb, 'chb', 'yri'),\n",
    "              ('-ej', ej_yri, 'yri', 'nea'),\n",
    "              ]\n",
    "\n",
    "    return momi.Demography(events, ('yri','chb'), (14,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a function that returns the expected\n",
    "TMRCA from the parameters, and then use `autograd` to compute its gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "[10.0, 0.1, 0.25, 0.03, 0.25, 1.0]\n",
      "Expected TMRCA:\n",
      "1.31277716218\n",
      "Gradient:\n",
      "[0.0045248167517458575, 0.55838496083537514, 0.28449869706692232, 3.9671067152725925, 0.83175299796270241, 0.13916390098743422]\n"
     ]
    }
   ],
   "source": [
    "# function mapping vector of parameters to the TMRCA of the corresponding demography\n",
    "def tmrca_func(params):\n",
    "    # equivalent to demo_func(params[0], params[1], params[2], ...)\n",
    "    demo = demo_func(*params)\n",
    "    # return expected TMRCA\n",
    "    return momi.expected_tmrca(demo)\n",
    "\n",
    "# use autograd.grad() to obtain the gradient function\n",
    "from autograd import grad\n",
    "tmrca_grad = grad(tmrca_func)\n",
    "\n",
    "x = [10., .1, .25, .03, .25, 1.]\n",
    "print \"Parameters:\"\n",
    "print x\n",
    "print \"Expected TMRCA:\"\n",
    "print tmrca_func(x)\n",
    "print \"Gradient:\"\n",
    "print tmrca_grad(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More details about using `autograd` for automatic differentiation\n",
    "\n",
    "`autograd` uses the magic of *operator overloading* to compute derivatives automatically.\n",
    "\n",
    "Here are a few rules to keep in mind, to make sure `autograd` works correctly:\n",
    "\n",
    "* Arithmetic operations `+,-,*,/,**` all work with autograd\n",
    "\n",
    "* For more complicated mathematical operations, use `autograd.numpy` and `autograd.scipy`, thinly wrapped versions of `numpy` and `scipy` that support auto-differentiation.\n",
    "    * For most users, `numpy` contains all the mathematical operations that are needed: `exp()`, `log()`, trigonemetric functions, matrix operations, fourier transform, etc.\n",
    "    * If needed, it is also possible to use autograd to define derivatives of your own mathematical operations.\n",
    "* Other do's and don'ts: (copy and pasted from autograd tutorial)\n",
    "    * Do use\n",
    "        * Most of `numpy`'s functions\n",
    "        * Most `numpy.ndarray` methods\n",
    "        * Some `scipy` functions\n",
    "        * Indexing and slicing of arrays `x = A[3, :, 2:4]`\n",
    "        * Explicit array creation from lists `A = np.array([x, y])`\n",
    "    * Don't use\n",
    "        * Assignment to arrays `A[0,0] = x`\n",
    "        * Implicit casting of lists to arrays `A = numpy.sum([x, y])`, use `A = numpy.sum(np.array([x, y]))` instead.\n",
    "        * `A.dot(B)` notation (use `np.dot(A, B)` instead)\n",
    "        * In-place operations (such as `a += b`, use `a = a + b` instead)\n",
    "\n",
    "Documentation for autograd can be found at https://github.com/HIPS/autograd/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Now let's try to infer the following demography from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_params = [10., .1, .25, .03, .25, 1.]\n",
    "true_demo = demo_func(*true_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate a new dataset with `ms` (or similar program, e.g. `scrm`, `macs`, `msprime`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ms_path provided, using SFS previously stored in tutorial_data.txt.\n"
     ]
    }
   ],
   "source": [
    "## to generate new dataset, change this to\n",
    "## ms_path = \"/path/to/ms\"\n",
    "ms_path = None\n",
    "#ms_path = os.environ[\"MS_PATH\"]\n",
    "\n",
    "if ms_path is not None:\n",
    "    print \"Generating new dataset with ms\"\n",
    "    \n",
    "    n_loci = 20\n",
    "    kb_per_locus = 500\n",
    "    mut_rate_per_kb, recom_rate_per_kb = 1.,1.\n",
    "    \n",
    "    ms_output = momi.simulate_ms(ms_path, true_demo, \n",
    "                                 n_loci, kb_per_locus * mut_rate_per_kb, \n",
    "                                 additional_ms_params=\"-r %f %d\" % (kb_per_locus*recom_rate_per_kb,\n",
    "                                                                    int(kb_per_locus * 1000)))\n",
    "    seg_sites = momi.seg_sites_from_ms(ms_output, sampled_pops=true_demo.sampled_pops)\n",
    "\n",
    "    sfs_list = momi.get_sfs_list(seg_sites)\n",
    "    combined_sfs = momi.sum_sfs_list(sfs_list)\n",
    "    \n",
    "    ## uncomment these lines to save the new dataset\n",
    "    #with open(data_filename,'w') as f:\n",
    "    #    momi.write_seg_sites(f, seg_sites)\n",
    "else:\n",
    "    print \"No ms_path provided, using SFS previously stored in %s.\" % data_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define (lower,upper) bounds on the parameter space\n",
    "bounds = [(.01, 100.),\n",
    "          (.01, 100.),\n",
    "          (.01,5.),\n",
    "          (.001,.25),\n",
    "          (.01,5.),\n",
    "          (.01,5.)]\n",
    "\n",
    "# pick a random start value for the parameter search\n",
    "import random\n",
    "lower_bounds, upper_bounds = [l for l,u in bounds], [u for l,u in bounds]\n",
    "start_params = [random.triangular(lower, upper, mode)\n",
    "                for lower, upper, mode in zip(lower_bounds, upper_bounds, [1, 1, 1, .1, 1,1,1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now search for the MCLE (max composite likelihood estimate) with **`momi.composite_mle_search()`**.\n",
    "\n",
    "By default, `momi.composite_mle_search()` assumes `demo_func` is differentiable with `autograd`, and uses the gradient in a hill-climbing algorithm.\n",
    "* If you don't want to use `autograd`, you can disable the gradient (i.e. jacobian) with:\n",
    "    * `momi.composite_mle_search(..., jac=False, ...)`\n",
    "* Conversely, `momi.composite_mle_search()` provides options for using the Hessian (second-order derivative), in addition to the gradient.\n",
    "    * See **`help(momi.composite_mle_search)`**.\n",
    "\n",
    "Beware that **`momi.composite_mle_search()`** can be vulnerable to local maxima.\n",
    "It isn't a problem in this example, but in other cases, you may have to try multiple starting positions to reach the global maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "objective ( [ 7.57941804  0.77204882  3.12772809  0.12996554  2.94179962  1.28238208] ) == 74041.4\n",
      "iter 25\n",
      "objective ( [  3.08230381e+01   1.00000000e-02   1.00000000e-02   1.25180626e-01   4.45735083e-01   2.43734775e-01] ) == 4532.87\n",
      "iter 50\n",
      "objective ( [ 6.12955022  0.06138432  0.01        0.15064413  0.54413005  0.08099848] ) == 3128.67\n",
      "iter 75\n",
      "objective ( [ 18.60179884   0.02346068   0.27496664   0.13726652   0.2281686    0.36147517] ) == 775.37\n",
      "iter 100\n",
      "objective ( [ 13.07266173   0.07073185   0.27770913   0.06411688   0.21931314   0.62521405] ) == 636.163\n",
      "iter 125\n",
      "objective ( [ 10.46994694   0.09766749   0.25851679   0.03568675   0.25452852   0.91000949] ) == 609.11\n",
      "iter 150\n",
      "objective ( [ 10.43306421   0.09825792   0.25819617   0.03518571   0.25504955   0.91959272] ) == 609.096\n"
     ]
    }
   ],
   "source": [
    "mcle_search_result = momi.composite_mle_search(combined_sfs, demo_func, start_params, \n",
    "                                              bounds = bounds, maxiter = 500, output_progress = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results:\n",
      "  status: 1\n",
      " success: True\n",
      "    nfev: 164\n",
      "     fun: 609.09631110844202\n",
      "       x: array([ 10.43286544,   0.09826013,   0.2581945 ,   0.03518365,\n",
      "         0.25505259,   0.91963437])\n",
      " message: 'Converged (|f_n-f_(n-1)| ~= 0)'\n",
      "     jac: array([ 0.00019125,  0.02477783,  0.01185449,  0.08726422,  0.0219017 ,\n",
      "        0.00148004])\n",
      "     nit: 35\n"
     ]
    }
   ],
   "source": [
    "print \"Search results:\"\n",
    "# print info such as whether search succeeded, number function/gradient evaluations, etc\n",
    "print mcle_search_result\n",
    "# note the printed function & gradient values are for -1*log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated params:\n",
      "[ 10.43286544   0.09826013   0.2581945    0.03518365   0.25505259\n",
      "   0.91963437]\n",
      "Ratio of Estimated/Truth:\n",
      "[ 1.04328654  0.98260133  1.03277799  1.17278822  1.02021036  0.91963437]\n"
     ]
    }
   ],
   "source": [
    "est_params = mcle_search_result.x\n",
    "print \"Estimated params:\"\n",
    "print est_params\n",
    "print \"Ratio of Estimated/Truth:\"\n",
    "print est_params / true_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at estimated parameters: -609.096311108\n",
      "Log-likelihood at true parameters: -620.223208703\n"
     ]
    }
   ],
   "source": [
    "print \"Log-likelihood at estimated parameters:\", -mcle_search_result.fun\n",
    "print \"Log-likelihood at true parameters:\", momi.composite_log_likelihood(combined_sfs, true_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Confidence Intervals\n",
    "\n",
    "As the number of independent loci goes to infinity,\n",
    "the MCLE is asymptotically Gaussian, with mean at the truth,\n",
    "and covariance given by the inverse 'Godambe information'.\n",
    "\n",
    "This can be used to construct approximate confidence intervals,\n",
    "which have the correct coverage properties in the limit (assuming certain regularity conditions, e.g. *identifiability* and *consistency*).\n",
    "\n",
    "`momi` currently has 2 methods for computing confidence intervals:\n",
    "* **iid**: Treats the loci as iid. \n",
    "    * Appropriate when there are many loci, roughly identically distributed.\n",
    "* **series**: Treat the segregating sites as a time series. \n",
    "    * Works for a small number loci, and they don't have to be identically distributed.\n",
    "    * Converges as number of SNPs per locus $\\to \\infty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing approximate covariance of MCLE...\n",
      "[[  2.83623120e-01  -2.22496489e-03   1.25416135e-03   9.62915545e-04\n",
      "   -2.99547984e-03  -1.35531531e-02]\n",
      " [ -2.22496489e-03   4.74062846e-05   2.23711712e-06  -2.87674454e-05\n",
      "    2.20243318e-05   5.43452250e-04]\n",
      " [  1.25416135e-03   2.23711712e-06   1.30071384e-04   8.36556947e-06\n",
      "   -1.06969840e-04   4.28419893e-04]\n",
      " [  9.62915545e-04  -2.87674454e-05   8.36556947e-06   3.88465261e-05\n",
      "   -1.97495089e-05  -6.14224853e-04]\n",
      " [ -2.99547984e-03   2.20243318e-05  -1.06969840e-04  -1.97495089e-05\n",
      "    1.69210714e-04  -1.55558427e-04]\n",
      " [ -1.35531531e-02   5.43452250e-04   4.28419893e-04  -6.14224853e-04\n",
      "   -1.55558427e-04   1.61664647e-02]]\n"
     ]
    }
   ],
   "source": [
    "print \"Computing approximate covariance of MCLE...\"\n",
    "\n",
    "## the approximate covariance matrix of the MCLE\n",
    "mcle_cov = momi.godambe_scaled_inv(\"series\", est_params, seg_sites, demo_func)\n",
    "print mcle_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate 95% confidence intervals for parameters:\n",
      "      Lower      Upper  Truth\n",
      "0  9.389062  11.476669  10.00\n",
      "1  0.084765   0.111755   0.10\n",
      "2  0.235841   0.280548   0.25\n",
      "3  0.022968   0.047400   0.03\n",
      "4  0.229557   0.280548   0.25\n",
      "5  0.670430   1.168839   1.00\n"
     ]
    }
   ],
   "source": [
    "# marginal confidence intervals (wald test)\n",
    "print \"Approximate 95% confidence intervals for parameters:\"\n",
    "\n",
    "import scipy.stats\n",
    "conf_lower, conf_upper = scipy.stats.norm.interval(.95, loc = est_params, scale = np.sqrt(np.diag(mcle_cov)))\n",
    "print pandas.DataFrame({\"Truth\" : true_params, \"Lower\" : conf_lower, \"Upper\" : conf_upper}, columns = [\"Lower\",\"Upper\",\"Truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate p-value of the residuals\n",
      "p =  0.513720697517\n"
     ]
    }
   ],
   "source": [
    "# wald test: residual * cov^{-1} * residual should be Chi-squared with n_params degrees of freedom\n",
    "print \"Approximate p-value of the residuals\"\n",
    "\n",
    "inv_cov = np.linalg.inv(mcle_cov)\n",
    "# make sure the numerical inverse is still symmetric\n",
    "assert np.allclose(inv_cov, inv_cov.T)\n",
    "inv_cov = (inv_cov + inv_cov.T) / 2.0\n",
    "\n",
    "resids = est_params - true_params\n",
    "wald_stat = np.dot(resids, np.dot(inv_cov, resids))\n",
    "print \"p = \", 1.-scipy.stats.chi2.cdf(wald_stat, df=len(resids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value of log-likelihood ratio\n",
      "0.6172\n"
     ]
    }
   ],
   "source": [
    "## log likelihood ratio test\n",
    "## has a nonstandard null distribution for composite likelihood, which we simulate from\n",
    "n_null_sims = 10000\n",
    "llr_p = momi.log_lik_ratio_p(\"series\", n_null_sims, est_params, true_params, [True] * len(true_params), \n",
    "                             seg_sites, demo_func)\n",
    "print \"p-value of log-likelihood ratio\"\n",
    "print llr_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value of log-likelihood ratio\n",
      "0.8376\n"
     ]
    }
   ],
   "source": [
    "## log likelihood for iid\n",
    "n_null_sims = 10000\n",
    "llr_p = momi.log_lik_ratio_p(\"iid\", n_null_sims, est_params, true_params, [True] * len(true_params), \n",
    "                             seg_sites, demo_func)\n",
    "print \"p-value of log-likelihood ratio\"\n",
    "print llr_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
