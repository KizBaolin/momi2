{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import momi\n",
    "\n",
    "# store momi logging output in logfile \"tutorial.log\"\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename=\"tutorial.log\", filemode=\"w\") \n",
    "# use level=logging.DEBUG for more verbose output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Use the **`help()`** function to view documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package momi:\n",
      "\n",
      "NAME\n",
      "    momi\n",
      "\n",
      "DESCRIPTION\n",
      "    momi (MOran Models for Inference) is a python package for computing the site frequency spectrum,\n",
      "    a summary statistic commonly used in population genetics, and using it to infer demographic history.\n",
      "    \n",
      "    Please refer to examples/tutorial.ipynb for usage & introduction.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    compute_sfs\n",
      "    concatenate_datasets\n",
      "    confidence_region\n",
      "    convolution\n",
      "    data (package)\n",
      "    demo_model\n",
      "    demo_plotter\n",
      "    demography\n",
      "    einsum2 (package)\n",
      "    events\n",
      "    fstats\n",
      "    likelihood\n",
      "    math_functions\n",
      "    moran_model\n",
      "    optimizers\n",
      "    parse_ms\n",
      "    size_history\n",
      "    util\n",
      "    vcf2momi\n",
      "\n",
      "FILE\n",
      "    /home/jack/.local/lib/python3.6/site-packages/momi/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(momi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Creating demographies\n",
    "\n",
    "momi uses a syntax based on the program ms by Richard Hudson.\n",
    "A demography is specified as a sequence of events.\n",
    "Time is measured going backwards from the present (t=0) to the past (t>0).\n",
    "\n",
    "There are 4 kinds of events:\n",
    "* **('-en', t, i, N)**\n",
    "    * At time t, population i has its scaled population size set to N, and growth rate set to 0.\n",
    "* **('-eg', t, i, g)**\n",
    "    * At time t, population i has exponential growth rate g (so for s>t, $N(s) = N(t) e^{(s-t)  g}$)\n",
    "* **('-ej', t, i, j)**\n",
    "    * At time t, all lineages in population i move into j.\n",
    "* **('-ep', t, i, j, p_ij)**\n",
    "    * At time t, each lineage in i moves into j with probability p_ij.\n",
    "\n",
    "Note **-en,-eg,-ej** are flags from ms, while **-ep** replaces the flag **-es** in ms.\n",
    "All parameters are scaled like in **ms**. That is, the population sizes are assumed to be rescaled by a \"reference\" size N_ref (e.g. 10,000), and time is scaled so there are 4*N_ref generations per unit time.\n",
    "\n",
    "Unlike ms, populations can be labeled by arbitrary strings. We illustrate this in the example below.\n",
    "\n",
    "See **`help(momi.Demography)`** or **`help(momi.Demography.__init__)`** for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### An example demography\n",
    "\n",
    "Now we consider a function for creating a demography from some parameters. This demography includes 2 sampled populations, **'yri'** and **'chb'**, with 14 and 10 alleles, respectively. The demography also involves admixture with a third population, **'nea'**.\n",
    "\n",
    "Note that for math functions, we use `autograd.numpy`, which is a drop-in replacement for `numpy` that allows for **automatic differentiation**. We will this in more detail in Section **\"Automatic differentiation and autograd\"**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "\n",
    "def demo_func(pulse_t, pulse_p,\n",
    "              dt_join_chb_yri, dt_join_yri_nea,\n",
    "              N_chb_bottom, N_chb_top,):\n",
    "    events = []\n",
    "\n",
    "    # \"chb\" receives a pulse from \"nea\"\n",
    "    # at time pulse_t and strength pulse_p\n",
    "    events.append(('-ep', pulse_t, 'chb', 'nea', pulse_p))\n",
    "\n",
    "    # going backwards-in-time by dt_join_chb_yri,\n",
    "    # \"chb\" joins onto \"yri\"\n",
    "    t_join_chb_yri = pulse_t + dt_join_chb_yri\n",
    "    events.append((\"-ej\", t_join_chb_yri, \"chb\", \"yri\"))\n",
    "\n",
    "    # going backwards-in-time by dt_join_yri_nea,\n",
    "    # \"yri\" joins onto \"nea\"\n",
    "    t_join_yri_nea = t_join_chb_yri + dt_join_yri_nea\n",
    "    events.append((\"-ej\", t_join_yri_nea, \"yri\", \"nea\"))\n",
    "\n",
    "    # at the present, \"chb\" has population size N_chb_bottom\n",
    "    events.append((\"-en\", 0, \"chb\", N_chb_bottom))\n",
    "\n",
    "    # \"chb\" has exponentially growing population size, so that\n",
    "    # it had size N_chb_top at time t_join_chb_yri\n",
    "    growth_rate_chb = -np.log(N_chb_top / N_chb_bottom) / t_join_chb_yri\n",
    "    events.append((\"-eg\", 0, \"chb\", growth_rate_chb))\n",
    "\n",
    "    # create the demography from these events, and\n",
    "    # specify \"yri\" and \"chb\" to have 14 and 10 alleles, respectively\n",
    "    return momi.make_demography(\n",
    "        events, sampled_pops=('yri','chb'), sampled_n=(14,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We set the \"true\" demography to have the following parameters.\n",
    "We will simulate some data from this demography and try to infer it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "true_params = [.25, .03, .25, 1., 10., .1]\n",
    "true_demo = demo_func(*true_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Simulating and reading data\n",
    "\n",
    "In this section we will simulate some data from the \"true\" demography.\n",
    "We will save it as vcf, and then show how to read data into momi from\n",
    "vcf format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Simulating data\n",
    "\n",
    "We simulate 20 loci of length 500 Kb and save them as vcfs.\n",
    "\n",
    "Note that the per-base mutation and recombination rates are in ms time\n",
    "units, i.e. the mutation rate is the number of mutations per 4*N_ref generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "\n",
    "per_base_mut_rate = .001\n",
    "per_base_recom_rate = .001\n",
    "bases_per_locus = int(5e5)\n",
    "n_loci = 20\n",
    "ploidy = 2\n",
    "\n",
    "# create data directory if it doesn't exist\n",
    "os.makedirs(\"data\", exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# simulate 20 \"chromosomes\", saving each in a separate gzipped vcf file\n",
    "for chrom in range(n_loci):\n",
    "    with gzip.open(\"data/{}.vcf.gz\".format(chrom), \"wt\") as outfile:\n",
    "        true_demo.simulate_vcf(\n",
    "            outfile,\n",
    "            mutation_rate=per_base_mut_rate,\n",
    "            recombination_rate=per_base_recom_rate,\n",
    "            length=bases_per_locus,\n",
    "            chrom_names=[\"chr{}\".format(chrom)],\n",
    "            ploidy=ploidy,\n",
    "            random_seed=1234+chrom) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Reading data from vcf\n",
    "\n",
    "We read the data into momi from the vcf files, using the function momi.SnpAlleleCounts.read_vcf().\n",
    "\n",
    "Aside from the vcf file itself, this function has 2 important parameters:\n",
    "1. **ind2pop**, a dict mapping samples to their populations\n",
    "2. **ancestral_alleles**, which tells momi how to determine which allele is the ancestral one. This parameter can take 3 possible values:\n",
    "  * If ancestral_alleles=True, then momi will read the ancestral allele from the \"AA\" INFO field. SNPs missing this field will be ignored.\n",
    "  *  If ancestral_alleles=False or None, then momi will assume that REF is the ancestral allele. (This is the case for the simulated data).\n",
    "  * If ancestral_alleles is the name of a population, then momi will treat that population as an outgroup, and use its allele as the ancestral one. (If the population contains both alleles, the SNP is ignored).\n",
    "\n",
    "If you don't know the ancestral allele, use ancestral_alleles=False; you can later tell momi to use the folded SFS, which ignores whether an allele is ancestral or derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Create dict mapping samples to populations\n",
    "ind2pop = {}\n",
    "for pop, n in zip(true_demo.sampled_pops, true_demo.sampled_n):\n",
    "    for i in range(int(n / ploidy)):\n",
    "        # in the vcf, the i-th individual\n",
    "        # in population p was named \"{p}_{i}\"\n",
    "        ind2pop[\"{}_{}\".format(pop, i)] = pop\n",
    "\n",
    "# No \"AA\" INFO field; use REF as the ancestral allele\n",
    "ancestral_alleles = None\n",
    "\n",
    "# Read in each vcf in a for loop\n",
    "data = []\n",
    "for chrom in range(n_loci):\n",
    "    with gzip.open(\"data/{}.vcf.gz\".format(chrom), \"rt\") as f:\n",
    "        data.append(momi.SnpAlleleCounts.read_vcf(f, ind2pop,\n",
    "                                                  ancestral_alleles))\n",
    "\n",
    "# concatenate the 20 loci into a single dataset\n",
    "data = momi.SnpAlleleCounts.concatenate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Saving data in custom json format\n",
    "\n",
    "Use the dump() method to save the data in a custom json format,\n",
    "which is quicker for momi to read then VCF.\n",
    "\n",
    "Use momi.SnpAlleleCounts.load() to load data saved in this json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "with gzip.open(\"data/momi_data.json.gz\", \"wt\") as f:\n",
    "    data.dump(f)\n",
    "\n",
    "with gzip.open(\"data/momi_data.json.gz\", \"rt\") as f:\n",
    "    data2 = momi.SnpAlleleCounts.load(f)\n",
    "\n",
    "assert data == data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Inference\n",
    "\n",
    "To do inference, we first create a likelihood surface by passing the data\n",
    "and demo_func to **momi.SfsLikelihoodSurface()**.\n",
    "\n",
    "Other parameters include the mutation rate, locus length,\n",
    "whether to use the folded SFS (recommended when the true ancestral allele is unknown),\n",
    "and a \"batch size\" for computing SFS entries in batches (reduce this to decrease memory usage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "surface = momi.SfsLikelihoodSurface(\n",
    "    data, demo_func,\n",
    "    # set mut_rate=None if you don't know the mutation rate\n",
    "    # can pass in lists for per-locus mut_rate/length\n",
    "    mut_rate=per_base_mut_rate, length=bases_per_locus,\n",
    "    # set folded=True if you don't know the ancestral allele\n",
    "    folded=False,\n",
    "    # decrease to reduce memory usage (compute SFS in smaller batches)\n",
    "    batch_size=1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "To find the MLE, call the method **momi.SfsLikelihoodSurface.find_mle**.\n",
    "\n",
    "This is essentially a wrapper around scipy.optimize.minimize, and takes many of the same arguments.\n",
    "Here, we pass in the starting point for the parameter search, (lower, upper) bounds for each parameter,\n",
    "and a callback function that prints every 5th step to STDOUT.\n",
    "\n",
    "The default method used for searching the parameter space is \"tnc\", which works well for a small\n",
    "number of parameters (roughly 20). For larger parameter spaces, the method \"L-BFGS-B\" is recommended.\n",
    "\n",
    "Note that this only finds a local optimum, it is recommended to try many random start points to find\n",
    "the true global maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# define (lower,upper) bounds on the parameter space\n",
    "bounds = [(.01,5.),\n",
    "          (1e-100,.25),\n",
    "          (.01,5.),\n",
    "          (.01,5.),\n",
    "          (.01, 100.),\n",
    "          (.01, 100.)]\n",
    "\n",
    "# pick a random start value for the parameter search\n",
    "import random\n",
    "x0 = [random.triangular(lower, upper, mode)\n",
    "      for (lower, upper), mode in zip(bounds, [1, 0.1, 1, 1, 1, 1])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  = 0, kl-divergence = 0.44196012155004366, x = [  0.8820758    0.22108438   0.5680652    1.61156889   0.47459644\n",
      "  79.6846602 ]\n",
      "iter  = 5, kl-divergence = 0.17734213359928547, x = [  6.82466812e-01   1.83935104e-01   1.00000000e-02   1.00000000e-02\n",
      "   4.90925576e-01   7.47057526e+01]\n",
      "iter  = 10, kl-divergence = 0.04967649324517103, x = [ 0.42619625  0.18224958  0.01        0.01        2.74017106  0.19570562]\n",
      "iter  = 15, kl-divergence = 0.01239511662971747, x = [  4.83133654e-01   1.68026632e-01   1.00000000e-02   1.56268277e-01\n",
      "   1.06762219e+01   1.29377722e-01]\n",
      "iter  = 20, kl-divergence = 0.007732855244792322, x = [  0.32968246   0.1557145    0.14158693   0.49921019  18.549751\n",
      "   0.03329411]\n",
      "iter  = 25, kl-divergence = 0.004384463133041531, x = [  0.29011707   0.10802974   0.2005829    0.35720525  18.42539448\n",
      "   0.03213004]\n",
      "iter  = 30, kl-divergence = 0.003245021898788344, x = [  0.27540549   0.03520088   0.22314636   0.70488392  11.06873796\n",
      "   0.08498184]\n",
      "iter  = 35, kl-divergence = 0.0031868945803772545, x = [  0.26335677   0.02472907   0.23893625   0.90710508  10.47159189\n",
      "   0.09426638]\n"
     ]
    }
   ],
   "source": [
    "# callback function to print every 5th step to STDOUT\n",
    "def callback(x):\n",
    "    if x.iteration % 5 == 0:\n",
    "        print (\"iter  = {0}, kl-divergence = {1}, x = {2}\".format(\n",
    "            x.iteration, x.fun, x))\n",
    "\n",
    "res = surface.find_mle(x0=x0, bounds=bounds, callback=callback,\n",
    "                       # use method=\"L-BFGS-B\" if >>20 parameters \n",
    "                       # use method=\"Nelder-Mead\" or method=\"Powell\" to avoid using gradients\n",
    "                       method=\"tnc\",\n",
    "                       options={'maxiter':250})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.0031868809268584238\n",
       "     jac: array([ -1.72553276e-06,   4.82393976e-06,   5.79543533e-06,\n",
       "         2.59469476e-07,  -1.05387104e-07,  -2.09438317e-05])\n",
       " message: 'Converged (|f_n-f_(n-1)| ~= 0)'\n",
       "    nfev: 195\n",
       "     nit: 37\n",
       "  status: 1\n",
       " success: True\n",
       "       x: array([  0.26323286,   0.02463737,   0.23913914,   0.9091638 ,\n",
       "        10.45866508,   0.09441628])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# info such as inferred x, whether search succeeded, number function/gradient evaluations, etc\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Inferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pulse_t</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.263233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pulse_p</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.024637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt_join_chb_yri</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.239139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dt_join_yri_nea</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.909164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N_chb_bottom</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.458665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N_chb_top</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.094416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Parameter  Truth   Inferred\n",
       "0          pulse_t   0.25   0.263233\n",
       "1          pulse_p   0.03   0.024637\n",
       "2  dt_join_chb_yri   0.25   0.239139\n",
       "3  dt_join_yri_nea   1.00   0.909164\n",
       "4     N_chb_bottom  10.00  10.458665\n",
       "5        N_chb_top   0.10   0.094416"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the inferred vs true parameters\n",
    "import inspect\n",
    "import pandas as pd\n",
    "pd.DataFrame(list(zip(inspect.signature(demo_func).parameters.keys(),\n",
    "                      true_params,\n",
    "                      res.x)),\n",
    "             columns=[\"Parameter\", \"Truth\", \"Inferred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Automatic diffentiation and autograd\n",
    "\n",
    "momi uses the package **autograd** to compute gradients of the likelihood surface.\n",
    "To ensure this works correctly, you should make sure demo_func() is compatible with autograd.\n",
    "\n",
    "You can avoid using autograd by using a non-gradient based method in momi.SfsLikelihoodSurface.find_mle(),\n",
    "such as method=\"Nelder-Mead\" or method=\"Powell\".\n",
    "Alternatively, you can use momi.SfsLikelihoodSurface.find_mle(..., jac=False, ...) to have the optimizer\n",
    "numerically approximate the gradient (but this is much slower than automatically computing it).\n",
    "See help(momi.SfsLikelihoodSurface.find_mle) for more details.\n",
    "\n",
    "Documentation for autograd can be found at https://github.com/HIPS/autograd/\n",
    "Some do's and don'ts for autograd (from the autograd tutorial):\n",
    "* Do use\n",
    "    * Arithmetic operations `+,-,*,/,**`\n",
    "    * Most of `numpy`'s functions\n",
    "    * Most `numpy.ndarray` methods\n",
    "    * Some `scipy` functions\n",
    "    * Indexing and slicing of arrays `x = A[3, :, 2:4]`\n",
    "    * Explicit array creation from lists `A = np.array([x, y])`\n",
    "* Don't use\n",
    "    * Assignment to arrays `A[0,0] = x`\n",
    "    * Implicit casting of lists to arrays `A = numpy.sum([x, y])`, use `A = numpy.sum(np.array([x, y]))` instead.\n",
    "    * `A.dot(B)` notation (use `numpy.dot(A, B)` instead)\n",
    "    * In-place operations (such as `a += b`, use `a = a + b` instead)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Other features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Computing individual SFS entries\n",
    "\n",
    "To compute individual SFS entries under a demography,\n",
    "first construct the entries (\"configurations\") to compute.\n",
    "These are represented in the form $((a_0,d_0),(a_1,d_1),...)$\n",
    "where there are $a_0$ ancestral and $d_0$ derived alleles in population 0, $a_1$ ancestral and $d_1$ derived alleles in population 1, etc.\n",
    "\n",
    "Then call momi.expected_sfs(), as below.\n",
    "See help(momi.expected_sfs) for options (e.g. folded SFS, sampling error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.01612258e+00,   9.71262945e-01,   9.74375162e-04,\n",
       "         2.70429603e-01,   5.54297456e-02,   1.44535809e-03])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of configs (index0 == yri, index1 == chb)\n",
    "configs = [( (14,0), (9,1), ), # 1 derived allele in chb\n",
    "           ( (13,1), (10,0), ), # 1 derived allele in yri \n",
    "           ( (11,3), (9,1),) , # 3 derived in yri, 1 derived in chb\n",
    "           ( (14,0), (0,10), ), # 0 derived in yri, all derived in chb\n",
    "           ( (2,12), (10,0), ), # 12 derived in yri, 0 derived in chb \n",
    "           ( (2,12), (2,8), ), # 12 derived in yri, 8 derived in chb\n",
    "          ]\n",
    "\n",
    "configs = momi.config_array((\"yri\",\"chb\"), configs)\n",
    "\n",
    "# the expected number of SNPs with the given configs for mut_rate=1.0\n",
    "momi.expected_sfs(true_demo, configs, mut_rate=1.0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Coalescent statistics\n",
    "\n",
    "`momi` can compute expected values of several coalescent statistics,\n",
    "such as the TMRCA (time to most recent common ancestor)\n",
    "and the total branch length of the genealogy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected TMRCA of all samples: \t 1.3124799948772297\n",
      "Expected TMRCA of chb samples: \t 0.8067087315312199\n",
      "Expected total branch length: \t 6.96253399983\n"
     ]
    }
   ],
   "source": [
    "eTmrca = momi.expected_tmrca(true_demo)\n",
    "print(\"Expected TMRCA of all samples:\", \"\\t\", eTmrca)\n",
    "\n",
    "eTmrca_chb = momi.expected_deme_tmrca(true_demo, 'chb')\n",
    "print(\"Expected TMRCA of chb samples:\", \"\\t\", eTmrca_chb)\n",
    "\n",
    "eL = momi.expected_total_branch_len(true_demo)\n",
    "print (\"Expected total branch length:\", \"\\t\", eL)\n",
    "\n",
    "# See help(momi.expected_tmrca), etc. for more details.\n",
    "# Advanced users can use momi.expected_sfs_tensor_prod()\n",
    "# to compute these and many other summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "You can also use autograd to compute the gradients of these statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.28442909,  3.9289342 ,  0.83158351,  0.13903447,  0.00452414,\n",
       "        0.55834569])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autograd\n",
    "\n",
    "# function mapping vector of parameters to the TMRCA of the corresponding demography\n",
    "def tmrca_func(params):\n",
    "    # equivalent to demo_func(params[0], params[1], params[2], ...)\n",
    "    demo = demo_func(*params)\n",
    "    # return expected TMRCA\n",
    "    return momi.expected_tmrca(demo)\n",
    "\n",
    "# use autograd.grad() to obtain the gradient function\n",
    "tmrca_grad = autograd.grad(tmrca_func)\n",
    "\n",
    "tmrca_grad(np.array(true_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Stochastic gradient descent\n",
    "\n",
    "Stochastic gradient descent uses a random subset of SNPs to estimate the\n",
    "gradient at each step. The expected value of the stochastic gradient\n",
    "is the true gradient, but the stochastic gradient has added noise.\n",
    "\n",
    "When there are many populations, the SFS will have many unique entries\n",
    "and will be very large, so stochastic gradient descent allows quicker\n",
    "exploration of the parameter space. It is particularly useful for\n",
    "finding a good starting point before performing full optimization.\n",
    "\n",
    "momi uses the ADAM algorithm to automatically adjust the stepsize\n",
    "during the search, however the user must specify an initial stepsize.\n",
    "\n",
    "momi also uses the SVRG algorithm to improve the accuracy of the\n",
    "stochastic gradient. If the \"svrg_epoch\" parameter is set to a positive\n",
    "integer k, then every k steps the optimizer will compute the full\n",
    "likelihood (on all SNPs), and use this to reduce the variance of the\n",
    "stochastic gradient.\n",
    "(See papers for \"Stochastic Variance Reduced Gradient\".) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  = 0, log-likelihood = 6.3705451424422455, x = [  1.89126506   0.22258848   1.58947994   1.88686106  20.69464169\n",
      "  81.32020079]\n",
      "iter  = 50, log-likelihood = 4.6914536332021575, x = [  1.18914131   0.13219203   0.99623141   1.19894784  12.90858392\n",
      "  50.44797898]\n",
      "iter  = 100, log-likelihood = 3.920382615777373, x = [  0.83707938   0.0837325    0.69655534   0.88425705   8.79136047\n",
      "  33.59674937]\n",
      "iter  = 150, log-likelihood = 3.540377837139492, x = [  0.64761737   0.05983157   0.53620527   0.72512278   6.40401632\n",
      "  23.58967058]\n",
      "iter  = 200, log-likelihood = 3.3352740470683804, x = [  0.53883032   0.04660341   0.44431983   0.63125918   4.86706141\n",
      "  17.05804193]\n"
     ]
    }
   ],
   "source": [
    "# put parameters on log-scale (this is usually easier to optimize)\n",
    "def demo_func2(*log_x):\n",
    "    return demo_func(*np.exp(np.array(log_x)))\n",
    "\n",
    "surface2 = momi.SfsLikelihoodSurface(\n",
    "    data, demo_func2,\n",
    "    mut_rate=per_base_mut_rate, length=bases_per_locus,\n",
    "    folded=False)\n",
    "\n",
    "# callback function to print every 5th step to STDOUT\n",
    "def callback(x):\n",
    "    if x.iteration % 50 == 0:\n",
    "        print (\"iter  = {0}, log-likelihood = {1}, x = {2}\".format(\n",
    "            x.iteration, x.fun, np.exp(x)))\n",
    "\n",
    "res2 = surface2.stochastic_find_mle(\n",
    "    x0=np.log(x0), snps_per_minibatch=10**4, stepsize=.01,\n",
    "    num_iters=250, bounds=np.log(bounds),\n",
    "    callback=callback,\n",
    "    # compute full likelihood every 25 epochs\n",
    "    # set svrg_epoch=-1 to avoid this\n",
    "    svrg_epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": null,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "name": "tutorial.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
